{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "from datetime import timedelta\n",
    "from scipy.stats import skewnorm\n",
    "import inspect, re\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import  metrics\n",
    "import time\n",
    "import progressbar\n",
    "import warnings\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegressionCV as LogReg\n",
    "\n",
    "               \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from WOE_Houston import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_10 = pd.read_csv('fy_10_augmented.csv')\n",
    "fy_11 = pd.read_csv('fy_11_augmented.csv')\n",
    "fy_12 = pd.read_csv('fy_12_augmented.csv')\n",
    "fy_13 = pd.read_csv('fy_13_augmented.csv')\n",
    "fy_14 = pd.read_csv('fy_14_augmented.csv')\n",
    "fy_15 = pd.read_csv('fy_15_augmented.csv')\n",
    "fy_16 = pd.read_csv('fy_16_augmented.csv')\n",
    "\n",
    "fy_list = [fy_10, fy_11, fy_12, fy_13, fy_14, fy_15, fy_16]\n",
    "\n",
    "del fy_10\n",
    "del fy_11\n",
    "del fy_12\n",
    "del fy_13\n",
    "del fy_14\n",
    "del fy_15\n",
    "del fy_16\n",
    "gc.collect()\n",
    "\n",
    "essentials = ['Unnamed: 0',\n",
    " 'Fund Id',\n",
    " 'Business Area',\n",
    " 'Fund Center Id',\n",
    " 'GL Account',\n",
    " 'GL Description',\n",
    " 'GL Category',\n",
    " 'GL Category Description',\n",
    " 'Revenue or Expenditure',\n",
    " 'Fiscal Year',\n",
    " 'Fund Name',\n",
    " 'Fund Type Descr',\n",
    " 'Business Area Name',\n",
    " 'Fund Center Name',\n",
    " 'Commitment Set Description',\n",
    " 'Original Budget',\n",
    " 'Current Budget',\n",
    " 'Actuals',\n",
    " '3Y_Past_Actuals',\n",
    " '2Y_Past_Actuals',\n",
    " '1Y_Past_Actuals',\n",
    " '2Y_1Y_Actuals_Mean',\n",
    " '3Y_2Y_1Y_Actuals_Mean',\n",
    " '3Y_Past_Original_Budget',\n",
    " '2Y_Past_Original_Budget',\n",
    " '1Y_Past_Original_Budget',\n",
    " '2Y_1Y_Original_Budget_Mean',\n",
    " '3Y_2Y_1Y_Original_Budget_Mean',\n",
    " '3Y_Past_OA_Difference',\n",
    " '2Y_Past_OA_Difference',\n",
    " '1Y_Past_OA_Difference',\n",
    " '2Y_1Y_OA_Difference_Mean',\n",
    " '3Y_2Y_1Y_OA_Difference_Mean',\n",
    " 'OA_Difference',\n",
    " 'Yearly Crime Index',\n",
    " 'Yearly Avg High Temp',\n",
    " 'Yearly Avg Low Temp',\n",
    " 'Yearly Rain Fall',\n",
    " 'Astros Playoff Rounds',\n",
    " 'Astros Yearly Attendance',\n",
    " 'Rockets Playoff Rounds',\n",
    " 'Texans Playoff Rounds',\n",
    " 'Texans Average Attendance',\n",
    " 'Rockets Total Attendance']\n",
    "\n",
    "dummies = ['Fund Name_Asset Forfeiture Fund - Justice',\n",
    " 'Fund Name_Asset Forfeiture Fund - State',\n",
    " 'Fund Name_Auto Dealers Fund',\n",
    " 'Fund Name_Building Inspection Fund',\n",
    " 'Fund Name_C&E-Civic Center Facility Revenue Fund',\n",
    " 'Fund Name_Cable Television Fund',\n",
    " 'Fund Name_Child Safety Fund',\n",
    " 'Fund Name_Digital Houston Special Revenue',\n",
    " 'Fund Name_Expansion of Recycling Program',\n",
    " 'Fund Name_Fleet Management Fund',\n",
    " 'Fund Name_GSD - In-House Renovation Revolving Fund',\n",
    " 'Fund Name_General Fund',\n",
    " 'Fund Name_Greater Houston Trans & Emer Center',\n",
    " 'Fund Name_HAS-Revenue Fund',\n",
    " 'Fund Name_Health Benefits Fund',\n",
    " 'Fund Name_Historic Preservation Fund',\n",
    " 'Fund Name_Houston Emergeny Center',\n",
    " 'Fund Name_Long-Term Disablility Plan Fund',\n",
    " 'Fund Name_Municipal Court Technology Fund',\n",
    " 'Fund Name_PWE-Combined Utility System Gen Pur Fund',\n",
    " 'Fund Name_PWE-Combined Utility System Oper Fund',\n",
    " 'Fund Name_PWE-W & S System Operating Fund',\n",
    " 'Fund Name_Park Special Revenue Fund',\n",
    " 'Fund Name_Parking Mangement Operating Fund',\n",
    " 'Fund Name_Police Special Services',\n",
    " 'Fund Name_Project Cost Recovery',\n",
    " 'Fund Name_Property & Casualty Fund',\n",
    " 'Fund Name_Stormwater Fund',\n",
    " 'Fund Name_Supplemental Environmental Proj',\n",
    " 'Fund Name_Workers Compensation Admin Fund',\n",
    " 'Fund Type Descr_Enterprise Funds',\n",
    " 'Fund Type Descr_General Funds',\n",
    " 'Fund Type Descr_Internal Services Funds',\n",
    " 'Fund Type Descr_Special Revenue Funds',\n",
    " 'Business Area Name_Admn. & Regulatory Affairs',\n",
    " 'Business Area Name_Business Opportunity',\n",
    " \"Business Area Name_City Controller's Office\",\n",
    " 'Business Area Name_City Council',\n",
    " 'Business Area Name_City Secretary',\n",
    " 'Business Area Name_Citywide General Government',\n",
    " 'Business Area Name_Convention and Entertainment',\n",
    " 'Business Area Name_Finance',\n",
    " 'Business Area Name_General Debt Services',\n",
    " 'Business Area Name_General Services Department',\n",
    " 'Business Area Name_Health & Human Services',\n",
    " 'Business Area Name_Housing and Community Devp.',\n",
    " 'Business Area Name_Houston Airport System (HAS)',\n",
    " 'Business Area Name_Houston Emergency Center (HEC)',\n",
    " 'Business Area Name_Houston Fire Department (HFD)',\n",
    " 'Business Area Name_Houston Police Department',\n",
    " 'Business Area Name_Human Resources Dept.',\n",
    " 'Business Area Name_Information Technology (IT)',\n",
    " 'Business Area Name_Legal Department',\n",
    " 'Business Area Name_Library',\n",
    " \"Business Area Name_Mayor's Office\",\n",
    " 'Business Area Name_Municipal Court Judicial',\n",
    " 'Business Area Name_Municipal Courts Department',\n",
    " 'Business Area Name_Parks & Recreation',\n",
    " 'Business Area Name_Planning & Development',\n",
    " 'Business Area Name_Public Works & Engineering-PWE',\n",
    " 'Business Area Name_Solid Waste Management',\n",
    " 'Commitment Set Description_50 - Total Expenditures',\n",
    " 'Business Area Name_Houston Police Department-HPD',\n",
    " 'Business Area Name_Houston Information Tech Svcs'\n",
    "]\n",
    "\n",
    "drop_list = [\n",
    "    \n",
    "    'Fund Name', \n",
    "    'Fund Type Descr', \n",
    "    'Business Area Name',\n",
    "    'Commitment Set Description',\n",
    "    'GL Description',\n",
    "    'GL Category Description',\n",
    "    'Revenue or Expenditure',\n",
    "    'Fund Type Descr',\n",
    "    'Fund Center Name'\n",
    "]\n",
    "\n",
    "\n",
    "for i, y in enumerate(fy_list):\n",
    "    fy_list[i] = pd.concat([y[essentials], y[dummies]], axis=1)\n",
    "    fy_list[i]['Over Budget'] = fy_list[i]['OA_Difference']>0\n",
    "    \n",
    "for i, y in enumerate(fy_list):\n",
    "    if i==0:\n",
    "        fy_list[i][\"1YP_OA_Diff_Over_80K\"]=999999999999999\n",
    "    else:\n",
    "        fy_list[i][\"1YP_OA_Diff_Over_80K\"]=0\n",
    "        over80k_index = fy_list[i].loc[(fy_list[i]['1Y_Past_OA_Difference'].apply(lambda x: abs(x))>80000.0)].index\n",
    "        fy_list[i].loc[over80k_index, '1YP_OA_Diff_Over_80K'] = 1\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "splits_to_try = [\n",
    "    \n",
    "                #predicting off \"two years\"\n",
    "                 [(0,1),(1,2),'10-11 to predict 11'],\n",
    "                 [(0,2),(2,3),'10-11 to predict 12'],\n",
    "                 [(0,3),(3,4),'10-12 to predict 13'],\n",
    "                 #[(0,3),(3,5),'10-12 to predict 13 and 14'],\n",
    "                 [(1,4),(4,5),'11-13 to predict 14'], \n",
    "                 #[(1,4),(4,6),'11-13 to predict 14 and 15'],\n",
    "                 [(2,5),(5,6),'12-14 to predict 15'],\n",
    "                 #[(2,5),(5,7),'12-14 to predict 15 and 16'],\n",
    "                 [(3,6),(6,7),'13-15 to predict 16'], \n",
    "    \n",
    "                #predicting off \"three\" years\n",
    "    \n",
    "                 [(0,4),(5,6),'10-13 to predict 14'],\n",
    "                 #[(0,4),(4,6),'10-13 to predict 14 and 15'],\n",
    "                 #[(0,4),(4,7),'10-13 to predict 14 and 15 and 16'],\n",
    "                 [(1,5),(5,6),'11-14 to predict 15'],\n",
    "                 #[(1,5),(5,7),'11-14 to predict 15 and 16'],\n",
    "                 [(2,6),(6,7),'12-15 to predict 16']\n",
    "                ]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_Houston_Budget.ipynb\n",
      "02_EDA.ipynb\n",
      "03_Getting_Cleaned_CSVs.ipynb\n",
      "04_H2o_Cleaned.ipynb\n",
      "05_Adding_One_Hot.ipynb\n",
      "06_Taking_Out_Fy16.ipynb\n",
      "07_Adding_One_Hot_2.ipynb\n",
      "08_Houston_EDA.ipynb\n",
      "09_Adding_Past_Actuals.ipynb\n",
      "10_xgb_h20_augmented.ipynb\n",
      "11_adding_fy16.ipynb\n",
      "12_xgb_h20_added_fy16.ipynb\n",
      "13_xgb_split_80K.ipynb\n",
      "14_xgb_other_splits.ipynb\n",
      "15_xgb_classifier.ipynb\n",
      "16_xgb_classifier_pcaWOE.ipynb\n",
      "17_xgb_add_council_data.ipynb\n",
      "18_classifier_regressor.ipynb\n",
      "19_EDA_Pandas_Profiling_Report.ipynb\n",
      "2010_clfpred\n",
      "2010_council.csv\n",
      "2010council\n",
      "2010council.csv\n",
      "2011_clfpred\n",
      "2011_council.csv\n",
      "2011council\n",
      "2011council.csv\n",
      "2012_clfpred\n",
      "2012_council.csv\n",
      "2012council\n",
      "2012council.csv\n",
      "2013_clfpred\n",
      "2013_council.csv\n",
      "2013council\n",
      "2013council.csv\n",
      "2014_clfpred\n",
      "2014_council.csv\n",
      "2014council\n",
      "2014council.csv\n",
      "2015_clfpred\n",
      "2015_council.csv\n",
      "2015council\n",
      "2015council.csv\n",
      "2016_clfpred\n",
      "2016_council.csv\n",
      "2016council\n",
      "2016council.csv\n",
      "20_More_EDA.ipynb\n",
      "21_regress_on_clf_preds-Copy1.ipynb\n",
      "22_xgboost.ipynb\n",
      "Houston Yearly Data - Sheet1 (1).csv\n",
      "Houston Yearly Data - Sheet1.csv\n",
      "Untitled.ipynb\n",
      "WOE_Houston.py\n",
      "__pycache__\n",
      "budget-vs-actuals-metadata (1).xlsx\n",
      "budget-vs-actuals-revenue-and-expenses-fy10-operating-budget.xlsx\n",
      "budget-vs-actuals-revenue-and-expenses-fy11-operating-budget.xlsx\n",
      "budget-vs-actuals-revenue-and-expenses-fy12-operating-budget.xlsx\n",
      "budget-vs-actuals-revenue-and-expenses-fy13-operating-budget.xlsx\n",
      "budget-vs-actuals-revenue-and-expenses-fy14-operating-budget.xlsx\n",
      "budget-vs-actuals-revenue-and-expenses-fy15-operating-budget.xlsx\n",
      "city_council_data.csv\n",
      "fy16-budget-vs-actuals-revenue-and-expenses.xls\n",
      "fy_10_augmented.csv\n",
      "fy_10_uniform.csv\n",
      "fy_11_augmented.csv\n",
      "fy_11_uniform.csv\n",
      "fy_12_augmented.csv\n",
      "fy_12_uniform.csv\n",
      "fy_13_augmented.csv\n",
      "fy_13_uniform.csv\n",
      "fy_14_augmented.csv\n",
      "fy_14_uniform.csv\n",
      "fy_15_augmented.csv\n",
      "fy_15_uniform.csv\n",
      "fy_16_augmented.csv\n",
      "legacy_data\n",
      "results_df.csv\n",
      "unique_df.csv\n",
      "unique_items.csv\n",
      "unique_items_16.csv\n",
      "xgb-random-grid-search-results-01.csv\n",
      "~$budget-vs-actuals-revenue-and-expenses-fy13-operating-budget.xlsx\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mayor</th>\n",
       "      <th>Controller</th>\n",
       "      <th>City Council District A</th>\n",
       "      <th>City Council District B</th>\n",
       "      <th>City Council District C</th>\n",
       "      <th>City Council District D</th>\n",
       "      <th>City Council District E</th>\n",
       "      <th>City Council District F</th>\n",
       "      <th>City Council District G</th>\n",
       "      <th>City Council District H</th>\n",
       "      <th>City Council District I</th>\n",
       "      <th>City Council District J</th>\n",
       "      <th>City Council District K</th>\n",
       "      <th>City Council At Large 1</th>\n",
       "      <th>City Council At Large 2</th>\n",
       "      <th>City Council At Large 3</th>\n",
       "      <th>City Council At Large 4</th>\n",
       "      <th>City Council At Large 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Parker</td>\n",
       "      <td>R Green</td>\n",
       "      <td>B Stardig</td>\n",
       "      <td>J Johnson</td>\n",
       "      <td>A Clutterbock</td>\n",
       "      <td>W Adams</td>\n",
       "      <td>M Sullivan</td>\n",
       "      <td>A Hoang</td>\n",
       "      <td>O Pennington</td>\n",
       "      <td>E Gonzalez</td>\n",
       "      <td>J Rodriguez</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>S Costello</td>\n",
       "      <td>S Lovell</td>\n",
       "      <td>M Noriega</td>\n",
       "      <td>C Bradford</td>\n",
       "      <td>J Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>Parker</td>\n",
       "      <td>R Green</td>\n",
       "      <td>B Stardig</td>\n",
       "      <td>J Johnson</td>\n",
       "      <td>A Clutterbock</td>\n",
       "      <td>W Adams</td>\n",
       "      <td>M Sullivan</td>\n",
       "      <td>A Hoang</td>\n",
       "      <td>O Pennington</td>\n",
       "      <td>E Gonzalez</td>\n",
       "      <td>J Rodriguez</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>S Costello</td>\n",
       "      <td>S Lovell</td>\n",
       "      <td>M Noriega</td>\n",
       "      <td>C Bradford</td>\n",
       "      <td>J Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>Parker</td>\n",
       "      <td>R Green</td>\n",
       "      <td>H Brown</td>\n",
       "      <td>J Davis</td>\n",
       "      <td>E Cohen</td>\n",
       "      <td>W Adams</td>\n",
       "      <td>M Sullivan</td>\n",
       "      <td>A Hoang</td>\n",
       "      <td>O Pennington</td>\n",
       "      <td>E Gonzalez</td>\n",
       "      <td>J Rodriguez</td>\n",
       "      <td>M Laster</td>\n",
       "      <td>L Green</td>\n",
       "      <td>S Costello</td>\n",
       "      <td>A Burks</td>\n",
       "      <td>M Noriega</td>\n",
       "      <td>C Bradford</td>\n",
       "      <td>J Christie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>Parker</td>\n",
       "      <td>R Green</td>\n",
       "      <td>H Brown</td>\n",
       "      <td>J Davis</td>\n",
       "      <td>E Cohen</td>\n",
       "      <td>W Adams</td>\n",
       "      <td>M Sullivan</td>\n",
       "      <td>A Hoang</td>\n",
       "      <td>O Pennington</td>\n",
       "      <td>E Gonzalez</td>\n",
       "      <td>J Rodriguez</td>\n",
       "      <td>M Laster</td>\n",
       "      <td>L Green</td>\n",
       "      <td>S Costello</td>\n",
       "      <td>A Burks</td>\n",
       "      <td>M Noriega</td>\n",
       "      <td>C Bradford</td>\n",
       "      <td>J Christie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>Parker</td>\n",
       "      <td>R Green</td>\n",
       "      <td>B Stardig</td>\n",
       "      <td>J Davis</td>\n",
       "      <td>E Cohen</td>\n",
       "      <td>D Boykins</td>\n",
       "      <td>D Martin</td>\n",
       "      <td>R Nguyen</td>\n",
       "      <td>O Pennington</td>\n",
       "      <td>E Gonzalez</td>\n",
       "      <td>R Gallegos</td>\n",
       "      <td>M Laster</td>\n",
       "      <td>L Green</td>\n",
       "      <td>S Costello</td>\n",
       "      <td>D Robison</td>\n",
       "      <td>M Kubosh</td>\n",
       "      <td>C Bradford</td>\n",
       "      <td>J Christie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Parker</td>\n",
       "      <td>C Brown</td>\n",
       "      <td>B Stardig</td>\n",
       "      <td>J Davis</td>\n",
       "      <td>E Cohen</td>\n",
       "      <td>D Boykins</td>\n",
       "      <td>D Martin</td>\n",
       "      <td>R Nguyen</td>\n",
       "      <td>O Pennington</td>\n",
       "      <td>E Gonzalez</td>\n",
       "      <td>R Gallegos</td>\n",
       "      <td>M Laster</td>\n",
       "      <td>L Green</td>\n",
       "      <td>S Costello</td>\n",
       "      <td>D Robison</td>\n",
       "      <td>M Kubosh</td>\n",
       "      <td>C Bradford</td>\n",
       "      <td>J Christie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>Turner</td>\n",
       "      <td>C Brown</td>\n",
       "      <td>B Stardig</td>\n",
       "      <td>J Davis</td>\n",
       "      <td>E Cohen</td>\n",
       "      <td>D Boykins</td>\n",
       "      <td>D Martin</td>\n",
       "      <td>S Le</td>\n",
       "      <td>G Travis</td>\n",
       "      <td>K Cisneros</td>\n",
       "      <td>R Gallegos</td>\n",
       "      <td>M Laster</td>\n",
       "      <td>L Green</td>\n",
       "      <td>M Knox</td>\n",
       "      <td>D Robison</td>\n",
       "      <td>M Kubosh</td>\n",
       "      <td>K Edwards</td>\n",
       "      <td>J Christie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mayor Controller City Council District A City Council District B  \\\n",
       "2010  Parker    R Green               B Stardig               J Johnson   \n",
       "2011  Parker    R Green               B Stardig               J Johnson   \n",
       "2012  Parker    R Green                 H Brown                 J Davis   \n",
       "2013  Parker    R Green                 H Brown                 J Davis   \n",
       "2014  Parker    R Green               B Stardig                 J Davis   \n",
       "2015  Parker    C Brown               B Stardig                 J Davis   \n",
       "2016  Turner    C Brown               B Stardig                 J Davis   \n",
       "\n",
       "     City Council District C City Council District D City Council District E  \\\n",
       "2010           A Clutterbock                 W Adams              M Sullivan   \n",
       "2011           A Clutterbock                 W Adams              M Sullivan   \n",
       "2012                 E Cohen                 W Adams              M Sullivan   \n",
       "2013                 E Cohen                 W Adams              M Sullivan   \n",
       "2014                 E Cohen               D Boykins                D Martin   \n",
       "2015                 E Cohen               D Boykins                D Martin   \n",
       "2016                 E Cohen               D Boykins                D Martin   \n",
       "\n",
       "     City Council District F City Council District G City Council District H  \\\n",
       "2010                 A Hoang            O Pennington              E Gonzalez   \n",
       "2011                 A Hoang            O Pennington              E Gonzalez   \n",
       "2012                 A Hoang            O Pennington              E Gonzalez   \n",
       "2013                 A Hoang            O Pennington              E Gonzalez   \n",
       "2014                R Nguyen            O Pennington              E Gonzalez   \n",
       "2015                R Nguyen            O Pennington              E Gonzalez   \n",
       "2016                    S Le                G Travis              K Cisneros   \n",
       "\n",
       "     City Council District I City Council District J City Council District K  \\\n",
       "2010             J Rodriguez                      na                      na   \n",
       "2011             J Rodriguez                      na                      na   \n",
       "2012             J Rodriguez                M Laster                 L Green   \n",
       "2013             J Rodriguez                M Laster                 L Green   \n",
       "2014              R Gallegos                M Laster                 L Green   \n",
       "2015              R Gallegos                M Laster                 L Green   \n",
       "2016              R Gallegos                M Laster                 L Green   \n",
       "\n",
       "     City Council At Large 1 City Council At Large 2 City Council At Large 3  \\\n",
       "2010              S Costello                S Lovell               M Noriega   \n",
       "2011              S Costello                S Lovell               M Noriega   \n",
       "2012              S Costello                 A Burks               M Noriega   \n",
       "2013              S Costello                 A Burks               M Noriega   \n",
       "2014              S Costello               D Robison                M Kubosh   \n",
       "2015              S Costello               D Robison                M Kubosh   \n",
       "2016                  M Knox               D Robison                M Kubosh   \n",
       "\n",
       "     City Council At Large 4 City Council At Large 5  \n",
       "2010              C Bradford                 J Jones  \n",
       "2011              C Bradford                 J Jones  \n",
       "2012              C Bradford              J Christie  \n",
       "2013              C Bradford              J Christie  \n",
       "2014              C Bradford              J Christie  \n",
       "2015              C Bradford              J Christie  \n",
       "2016               K Edwards              J Christie  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houston_data = pd.read_csv(\"city_council_data.csv\")\n",
    "houston_data_columns = houston_data.iloc[0,1:].values\n",
    "houston_data_index = houston_data.iloc[2:,0].values\n",
    "houston_data  = houston_data.iloc[1:,1:]\n",
    "houston_data\n",
    "\n",
    "# houston_data.index= houston_data_index\n",
    "houston_data.columns = houston_data_columns\n",
    "# #houston_data.columns = ['2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017',\n",
    "# #       '2018', '2019']\n",
    "# houston_data.fillna(0, inplace=True)\n",
    "houston_data_index = [str(int(x)) for x in houston_data.index]\n",
    "houston_data = houston_data.T\n",
    "houston_data.columns = ['2010', '2011', '2012', '2013', '2014', '2015', '2016']\n",
    "# #       '2018', '2019']\n",
    "# houston_data = houston_data.T\n",
    "houston_data = houston_data.T\n",
    "houston_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_houston_data(year_df, houston_data, index):\n",
    "    for col in houston_data.columns:\n",
    "        if index ==0:\n",
    "            year_df[col] = 'na'\n",
    "        else:\n",
    "            year_df[col] = houston_data.iloc[index][col]\n",
    "        \n",
    "    return year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houston_columns = list(houston_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_index, year in enumerate(fy_list):\n",
    "    #fy_list[year_index].drop(['col'], axis=1, inplace=True)\n",
    "    fy_list[year_index] = add_houston_data(year, houston_data, year_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_list[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houston_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([year for year in fy_list])\n",
    "dummies = pd.get_dummies(df[list(houston_data.columns)]) # One-hot encoding of categorical variables\n",
    "df = pd.concat([dummies, df.drop(list(houston_data.columns), axis=1)], axis=1)\n",
    "    #fy_list[year_index].drop([list(houston_data.columns)], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(fy_list):\n",
    "    year = int('201'+str(i))\n",
    "    fy_list[i] = df.loc[df['Fiscal Year']==year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(fy_list):\n",
    "    fy_list[i].to_csv('201'+str(i)+'_council.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv(\"2012_council.csv\")\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iv_list = []\n",
    "for i, y in enumerate(fy_list):\n",
    "    train_iv, train_IV_series = data_vars(fy_list[i].drop(['OA_Difference','Actuals','Over Budget','Current Budget'], axis=1),  fy_list[i]['Over Budget'])\n",
    "    train_iv_list.append([train_iv, train_IV_series])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iv_list[2][1].sort_values(ascending=False, by='IV').loc[train_iv_list[2][1]['STRENGTH']!='useless']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_vars = []\n",
    "for i, item in enumerate(train_iv_list):\n",
    "    quantile = train_iv_list[i][1]['IV'].quantile(.6)\n",
    "    print(quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iv_list[i][1].sort_values(ascending=False, by='IV').loc[train_iv_list[i][1]['IV']<=.002][['VAR_NAME','IV']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_vars = []\n",
    "for i, item in enumerate(train_iv_list):\n",
    "    year_keep = list(train_iv_list[i][1].sort_values(ascending=False, by='IV').loc[train_iv_list[i][1]['IV']>=.003]['VAR_NAME'])\n",
    "    if i==0:\n",
    "        keep_vars = year_keep\n",
    "        #print(len(year_keep))\n",
    "    else:\n",
    "        keep_vars = list(set(year_keep) | set(keep_vars))\n",
    "        #print(len(year_keep))\n",
    "        \n",
    "\n",
    "drop_vars = set(set(list(fy_list[0].columns)).symmetric_difference(keep_vars))\n",
    "drop_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pd.Series(keep_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_vars += ['Fiscal Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keep_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fy_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-72eec1e053ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwoe_pca_explained_var_ratio_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwoe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWoeEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Over Budget'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fy_list' is not defined"
     ]
    }
   ],
   "source": [
    "woe_pca_df_list = []\n",
    "woe_pca_explained_var_ratio_list = []\n",
    "\n",
    "for i, y in enumerate(fy_list):\n",
    "    woe = WoeEncoder(columns=keep_vars, suffix='')\n",
    "    target = 'Over Budget'\n",
    "    y = fy_list[i][target]\n",
    "    \n",
    "    hold_df = woe.fit_transform(fy_list[i], y)\n",
    "    \n",
    "    pca = PCA(n_components=50)\n",
    "    \n",
    "    X = hold_df[keep_columns].fillna(0)\n",
    "    del hold_df; gc.collect()\n",
    "    \n",
    "    woe_pca_df_list.append(pca.fit(X))\n",
    "    woe_pca_explained_var_ratio_list.append(pca.explained_variance_ratio_.sum())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12:37 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_list[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bar = progressbar.ProgressBar()\n",
    "\n",
    "# hold_list = []\n",
    "# for split in splits_to_try:\n",
    "    \n",
    "#     hold_dict = {}\n",
    "    \n",
    "#     X_train = pd.concat([x for x in fy_list[split[0][0]:split[0][1]]])\n",
    "#     y_train = X_train['Over Budget']\n",
    "#     X_train.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "#     X_test = pd.concat([x for x in fy_list[split[1][0]:split[1][1]]])\n",
    "#     y_test = X_test['Over Budget']\n",
    "#     y_original_budget = X_test['Original Budget']\n",
    "#     X_test.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "\n",
    "#     model = xgb.XGBClassifier() #subsample= 0.8, min_child_weight= 1, max_depth= 4, gamma= 1, colsample_bytree= 1.0)\n",
    "#     model.fit(X_train,y_train)\n",
    "\n",
    "#     xgb_test_predictions = model.predict(X_test)\n",
    "#     xgb_train_predictions = model.predict(X_train)\n",
    "\n",
    "#     model_test_auc = metrics.roc_auc_score(y_test, xgb_test_predictions)\n",
    "#     model_train_auc = metrics.roc_auc_score(y_train, xgb_train_predictions)\n",
    "#     original_budget_auc = metrics.roc_auc_score(y_test, y_original_budget)\n",
    "    \n",
    "#     hold_dict.update({'split': split[2]})\n",
    "#     hold_dict.update({'model_test_auc': model_test_auc})\n",
    "#     hold_dict.update({'model_train_auc': model_train_auc})\n",
    "#     hold_dict.update({'original_budget_auc': original_budget_auc})\n",
    "    \n",
    "    \n",
    "#     hold_list.append(hold_dict)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(hold_list)\n",
    "# results_df['Model Improvement'] = results_df['model_test_auc']-results_df['original_budget_auc']\n",
    "# results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df['model_test_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##adding binary predictor as a feature for XGBReggresor to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_list = []\n",
    "fy_augmented = []\n",
    "for index, split in enumerate(splits_to_try):\n",
    "    \n",
    "    hold_dict = {}\n",
    "    \n",
    "    X_train = pd.concat([x for x in fy_list[split[0][0]:split[0][1]]])\n",
    "    y_train = X_train['Over Budget']\n",
    "    X_train.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "    X_test = pd.concat([x for x in fy_list[split[1][0]:split[1][1]]])\n",
    "    y_test = X_test['Over Budget']\n",
    "    y_original_budget = X_test['Original Budget']\n",
    "    X_test.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "\n",
    "    model = xgb.XGBClassifier() #subsample= 0.8, min_child_weight= 1, max_depth= 4, gamma= 1, colsample_bytree= 1.0)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    xgb_test_predictions = model.predict(X_test)\n",
    "    xgb_train_predictions = model.predict(X_train)\n",
    "    \n",
    "    xgb_test_predictions_probability = [x[1] for x in model.predict_proba(X_test)]\n",
    "    xgb_train_predictions_probability = [x[1] for x in model.predict_proba(X_train)]\n",
    "\n",
    "    model_test_auc = metrics.roc_auc_score(y_test, xgb_test_predictions)\n",
    "    model_train_auc = metrics.roc_auc_score(y_train, xgb_train_predictions)\n",
    "    original_budget_auc = metrics.roc_auc_score(y_test, y_original_budget)\n",
    "    \n",
    "    if index <= 5:\n",
    "        hold_df = pd.concat([x for x in fy_list[split[1][0]:split[1][1]]]) #grab the test dataframe\n",
    "        hold_df['Over_Budget_Prediction'] = xgb_test_predictions_probability #add in the over under budget predictions\n",
    "        fy_augmented.append(hold_df) #store it back in the fy_list\n",
    "    \n",
    "    \n",
    "    hold_dict.update({'split': split[2]})\n",
    "    hold_dict.update({'model_test_auc': model_test_auc})\n",
    "    hold_dict.update({'model_train_auc': model_train_auc})\n",
    "    hold_dict.update({'original_budget_auc': original_budget_auc})\n",
    "    hold_dict.update({'model':model})\n",
    "    \n",
    "    \n",
    "    \n",
    "    hold_list.append(hold_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(hold_list)\n",
    "results_df['Model Improvement'] = results_df['model_test_auc']-results_df['original_budget_auc']\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(fy_list):\n",
    "    if i ==0:\n",
    "        None\n",
    "    else:\n",
    "        fy_list[i] = fy_augmented[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_list[6][['Over_Budget_Prediction','OA_Difference']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_to_try = [\n",
    "    \n",
    "                #predicting off \"two years\"\n",
    "                 #[(0,1),(1,2),'10-11 to predict 11'],\n",
    "                 #[(0,2),(2,3),'10-11 to predict 12'],\n",
    "                 #[(0,3),(3,4),'10-12 to predict 13'],\n",
    "                 #[(0,3),(3,5),'10-12 to predict 13 and 14'],\n",
    "                 [(1,4),(4,5),'11-13 to predict 14'], \n",
    "                 #[(1,4),(4,6),'11-13 to predict 14 and 15'],\n",
    "                 [(2,5),(5,6),'12-14 to predict 15'],\n",
    "                 #[(2,5),(5,7),'12-14 to predict 15 and 16'],\n",
    "                 [(3,6),(6,7),'13-15 to predict 16'], \n",
    "    \n",
    "                #predicting off \"three\" years\n",
    "    \n",
    "                 #[(0,4),(5,6),'10-13 to predict 14'],\n",
    "                 #[(0,4),(4,6),'10-13 to predict 14 and 15'],\n",
    "                 #[(0,4),(4,7),'10-13 to predict 14 and 15 and 16'],\n",
    "                 [(1,5),(5,6),'11-14 to predict 15'],\n",
    "                 #[(1,5),(5,7),'11-14 to predict 15 and 16'],\n",
    "                 [(2,6),(6,7),'12-15 to predict 16']\n",
    "                ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#predicting Actuals with binary classifier \"over budget\" prediction as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_list = []\n",
    "for split in splits_to_try:\n",
    "    \n",
    "    hold_dict = {}\n",
    "    \n",
    "    X_train = pd.concat([x for x in fy_list[split[0][0]:split[0][1]]])\n",
    "    y_train = X_train['Actuals']\n",
    "    X_train.drop(['OA_Difference','Actuals','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "    X_test = pd.concat([x for x in fy_list[split[1][0]:split[1][1]]])\n",
    "    y_test = X_test['Actuals']\n",
    "    y_original_budget = X_test['Original Budget']\n",
    "    X_test.drop(['OA_Difference','Actuals','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "\n",
    "    model = xgb.XGBRegressor(subsample= 0.8, min_child_weight= 1, max_depth= 4, gamma= 1, colsample_bytree= 1.0)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    xgb_test_predictions = model.predict(X_test)\n",
    "    xgb_train_predictions = model.predict(X_train)\n",
    "\n",
    "    model_test_RMSE = np.sqrt(np.mean((xgb_test_predictions-y_test)**2))\n",
    "    model_train_RMSE = np.sqrt(np.mean((xgb_train_predictions-y_train)**2))\n",
    "    original_budget_RMSE = np.sqrt(np.mean((y_original_budget-y_test)**2))\n",
    "\n",
    "    hold_dict.update({'split': split[2]})\n",
    "    hold_dict.update({'model_test_RMSE': model_test_RMSE})\n",
    "    hold_dict.update({'model_train_RMSE': model_train_RMSE})\n",
    "    hold_dict.update({'original_budget_RMSE': original_budget_RMSE})\n",
    "    \n",
    "    \n",
    "    hold_list.append(hold_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(hold_list)\n",
    "results_df['Model Improvement'] = results_df['original_budget_RMSE']-results_df['model_test_RMSE']\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fy_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-13a331dd07ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fy_list' is not defined"
     ]
    }
   ],
   "source": [
    "fy_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_to_try_2 = [\n",
    "    \n",
    "                #predicting off \"two years\"\n",
    "    \n",
    "                 [(0,3),(3,4),'10-12 to predict 13'],\n",
    "                 [(0,3),(3,5),'10-12 to predict 13 and 14'],\n",
    "                 [(1,4),(4,5),'11-13 to predict 14'], \n",
    "                 [(1,4),(4,6),'11-13 to predict 14 and 15'],\n",
    "                 [(2,5),(5,6),'12-14 to predict 15'],\n",
    "                 [(2,5),(5,7),'12-14 to predict 15 and 16'],\n",
    "                 [(3,6),(6,7),'13-15 to predict 16'], \n",
    "    \n",
    "                #predicting off \"three\" years\n",
    "    \n",
    "                 [(0,4),(5,6),'10-13 to predict 14'],\n",
    "                 [(0,4),(4,6),'10-13 to predict 14 and 15'],\n",
    "                 [(0,4),(4,7),'10-13 to predict 14 and 15 and 16'],\n",
    "                 [(1,5),(5,6),'11-14 to predict 15'],\n",
    "                 [(1,5),(5,7),'11-14 to predict 15 and 16'],\n",
    "                 [(2,6),(6,7),'12-15 to predict 16']\n",
    "    \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hold_list = []\n",
    "for split in splits_to_try_2:\n",
    "    \n",
    "    hold_dict = {}\n",
    "    \n",
    "    X_train = pd.concat([x for x in fy_list[split[0][0]:split[0][1]]])\n",
    "    y_train = X_train['Over Budget']\n",
    "    X_train.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "    X_test = pd.concat([x for x in fy_list[split[1][0]:split[1][1]]])\n",
    "    y_test = X_test['Over Budget']\n",
    "    y_original_budget = X_test['Original Budget']\n",
    "    X_test.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "\n",
    "    model = xgb.XGBClassifier() #subsample= 0.8, min_child_weight= 1, max_depth= 4, gamma= 1, colsample_bytree= 1.0)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    xgb_test_predictions = model.predict(X_test)\n",
    "    xgb_train_predictions = model.predict(X_train)\n",
    "\n",
    "    model_test_auc = metrics.roc_auc_score(y_test, xgb_test_predictions)\n",
    "    model_train_auc = metrics.roc_auc_score(y_train, xgb_train_predictions)\n",
    "    original_budget_auc = metrics.roc_auc_score(y_test, y_original_budget)\n",
    "    \n",
    "    hold_dict.update({'split': split[2]})\n",
    "    hold_dict.update({'model_test_auc': model_test_auc})\n",
    "    hold_dict.update({'model_train_auc': model_train_auc})\n",
    "    hold_dict.update({'original_budget_auc': original_budget_auc})\n",
    "    \n",
    "    \n",
    "    hold_list.append(hold_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(hold_list)\n",
    "results_df['Model Improvement'] = results_df['model_test_auc']-results_df['original_budget_auc']\n",
    "results_df[['model_test_auc','model_train_auc','split']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['model_test_auc'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hold_list = []\n",
    "for split in splits_to_try[1:4]\n",
    "    \n",
    "hold_dict = {}\n",
    "    \n",
    "    X_train = pd.concat([x for x in fy_list[split[0][0]:split[0][1]]])\n",
    "    y_train = X_train['Over Budget']\n",
    "    X_train.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "    X_test = pd.concat([x for x in fy_list[split[1][0]:split[1][1]]])\n",
    "    y_test = X_test['Over Budget']\n",
    "    y_original_budget = X_test['Original Budget']\n",
    "    X_test.drop(['OA_Difference','Actuals','Over Budget','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "\n",
    "    model = xgb.XGBClassifier() #subsample= 0.8, min_child_weight= 1, max_depth= 4, gamma= 1, colsample_bytree= 1.0)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    xgb_test_predictions = model.predict(X_test)\n",
    "    xgb_train_predictions = model.predict(X_train)\n",
    "\n",
    "    model_test_auc = metrics.roc_auc_score(y_test, xgb_test_predictions)\n",
    "    model_train_auc = metrics.roc_auc_score(y_train, xgb_train_predictions)\n",
    "    original_budget_auc = metrics.roc_auc_score(y_test, y_original_budget)\n",
    "    \n",
    "    hold_dict.update({'split': split[2]})\n",
    "    hold_dict.update({'model_test_auc': model_test_auc})\n",
    "    hold_dict.update({'model_train_auc': model_train_auc})\n",
    "    hold_dict.update({'original_budget_auc': original_budget_auc})\n",
    "    \n",
    "    \n",
    "    hold_list.append(hold_dict)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(hold_list)\n",
    "results_df['Model Improvement'] = results_df['model_test_auc']-results_df['original_budget_auc']\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Model Improvement'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_list = []\n",
    "for split in splits_to_try:\n",
    "    \n",
    "    hold_dict = {}\n",
    "    \n",
    "    X_train = pd.concat([x for x in fy_list[split[0][0]:split[0][1]]])\n",
    "    y_train = X_train['Actuals']\n",
    "    X_train.drop(['OA_Difference','Actuals','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "    X_test = pd.concat([x for x in fy_list[split[1][0]:split[1][1]]])\n",
    "    y_test = X_test['Actuals']\n",
    "    y_original_budget = X_test['Original Budget']\n",
    "    X_test.drop(['OA_Difference','Actuals','Current Budget'] + drop_list, axis=1, inplace=True)\n",
    "\n",
    "    model = xgb.XGBClassifier(subsample= 0.8, min_child_weight= 1, max_depth= 4, gamma= 1, colsample_bytree= 1.0)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    xgb_test_predictions = model.predict(X_test)\n",
    "    xgb_train_predictions = model.predict(X_train)\n",
    "\n",
    "    model_test_auc = metrics.roc(y_test, xgb_test_predictions)\n",
    "    model_train_auc = metrics.roc(y_train, xgb_train_predictions)\n",
    "    original_budget_auc = metrics.roc(y_test, y_original_budget)\n",
    "    \n",
    "    hold_dict.update({'split': split[2]})\n",
    "    hold_dict.update({'model_test_auc': model_test_auc})\n",
    "    hold_dict.update({'model_train_auc': model_train_auc})\n",
    "    hold_dict.update({'original_budget_auc': original_budget_auc})\n",
    "    \n",
    "    \n",
    "    hold_list.append(hold_dict)\n",
    "    \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(hold_list)\n",
    "results_df['Model Improvement'] = results_df['model_test_auc']-results_df['original_budget_auc']\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[[0,2,4,6,7,10]]['Model Improvement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(hold_list)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sum_error = np.sum(abs(xgb_test_predictions-y_test))\n",
    "model_sum_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_sum_error = np.sum(abs(y_original_budget-y_test))\n",
    "budget_sum_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model precision over budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('$',round(budget_sum_error-model_sum_error,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "x = np.linspace(-1000000000,1000000000,1000000000)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(y_train, xgb_train_predictions, c='red', alpha=.95)\n",
    "plt.scatter(y_test, xgb_test_predictions, c='blue', alpha=.95)\n",
    "plt.scatter(y_test, y_original_budget, c='green', alpha=.95)\n",
    "plt.plot(x,x,c='black')\n",
    "plt.xlim([-5,1000000000])\n",
    "plt.ylim([-5,1000000000])\n",
    "plt.xlabel('observations')\n",
    "plt.ylabel('predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = model.get_booster().get_score(importance_type=\"weight\")\n",
    "weight_df = pd.DataFrame(weight_dict, index=range(len(weight_dict)))\n",
    "weight_df.T[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test , xgb_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=2.5)\n",
    "bins = np.arange(0,90000,90000/50)\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "\n",
    "sns.distplot(y_test, label='2015 Actuals',color='green', norm_hist=True, bins=bins, kde=False,  ax = ax)\n",
    "sns.distplot(xgb_test_predictions, label='XGB_test_predictions 2015',color='black', norm_hist=True, bins=bins, kde=True,  ax = ax)\n",
    "sns.distplot(y_original_budget, label='2015_original_budget',color='blue',norm_hist=True, bins=bins, kde=True,  ax = ax)\n",
    "    \n",
    "ax.set_title(\" \")\n",
    "ax.set_ylabel(\" \")\n",
    "ax.set_xlabel(\" \")\n",
    "ax.set_xlim(0,90000)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_budget_residuals = fy_15['Original Budget']-fy_15['Actuals']\n",
    "model_residuals = xgb_test_predictions-y_test\n",
    "hold_df = pd.DataFrame()\n",
    "hold_df['Original Budget Residuals'] = original_budget_residuals\n",
    "hold_df['Model Residuals'] = model_residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(model_residuals**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(original_budget_residuals**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_residuals_series = pd.Series(model_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_budget_residuals_series =pd.Series(original_budget_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_df = pd.DataFrame()\n",
    "residuals_df['Model_Residuals'] = model_residuals_series\n",
    "residuals_df['Original_Budget_Residuals'] = original_budget_residuals_series\n",
    "\n",
    "extreme_residuals = residuals_df.loc[(residuals_df['Model_Residuals']>=80000) | (residuals_df['Model_Residuals']<=-80000) | (residuals_df['Original_Budget_Residuals']>=80000) | (residuals_df['Original_Budget_Residuals']<=-80000) ] \n",
    "residuals_under_80K = residuals_df.loc[(residuals_df['Model_Residuals']<80000) & (residuals_df['Model_Residuals']>-80000) & (residuals_df['Original_Budget_Residuals']<=80000) & (residuals_df['Original_Budget_Residuals']>=-80000) ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Extreme Resisduals:           ',int(np.sqrt(np.mean(extreme_residuals['Model_Residuals']**2))), '\\nOriginal Budget Extreme Resisduals: ',  int(np.sqrt(np.mean(extreme_residuals['Original_Budget_Residuals']**2))))\n",
    "print(' ')\n",
    "print('Model Under 80K Resisduals:           ',int(np.sqrt(np.mean(residuals_under_80K['Model_Residuals']**2))), '\\nOriginal Budget Under 80K Resisduals: ',  int(np.sqrt(np.mean(residuals_under_80K['Original_Budget_Residuals']**2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=2.5)\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "bins_ = np.arange(-80000,80000,80000/50)\n",
    "\n",
    "sns.distplot(model_residuals, label='Model Residuals', norm_hist=True, bins = bins_, color='green',   ax = ax)\n",
    "sns.distplot(original_budget_residuals, label='Original Budget Residuals',bins=bins_, color='black',  ax = ax)\n",
    "    \n",
    "ax.set_title(\" \")\n",
    "ax.set_ylabel(\" \")\n",
    "ax.set_xlabel(\" \")\n",
    "ax.set_xlim(-80000,80000)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "\n",
    "train_df = pd.concat([fy_list[0], fy_list[1], fy_list[2], fy_list[3], fy_list[4]])\n",
    "Y = train_df['Actuals'].values\n",
    "X = train_df.drop(['OA_Difference','Actuals','Current Budget'] + drop_list, axis=1)\n",
    "test_df = pd.concat([fy_list[5], fy_list[6]])\n",
    "test = test_df.drop(['OA_Difference','Actuals','Current Budget'] + drop_list, axis=1)\n",
    "y_test = test_df['Actuals']\n",
    "original_budget = test_df['Original Budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(learning_rate=.02, n_estimators=600, silent=True, nthread=1)\n",
    "\n",
    "#xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "  #                  silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=param_comb, n_jobs=4, verbose=3, random_state=1001 )\n",
    "\n",
    "#cv=skf.split(X,Y)\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(X, Y)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_predictions = random_search.predict(test)\n",
    "#results_df = pd.DataFrame(data={'Actuals':y_test[:,1]})\n",
    "#results_df.to_csv('submission-random-grid-search-xgb-porto-01.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_RMSE = np.sqrt(np.mean((xgb_test_predictions-y_test)**2))\n",
    "#model_train_RMSE = np.sqrt(np.mean((xgb_train_predictions-y_train)**2))\n",
    "original_budget_RMSE = np.sqrt(np.mean((original_budget-y_test)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_original_budget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =pd.Series([7,8,9,10])\n",
    "b=pd.Series([1,2,1])\n",
    "np.mean([36,36,64])\n",
    "np.mean((a-b)**2)\n",
    "original_budget[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFramey_original_budget[:1000].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_budget_RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = random_search.best_estimator_.get_booster().get_score(importance_type=\"weight\")\n",
    "weight_df = pd.DataFrame(weight_dict, index=range(len(weight_dict)))\n",
    "weight_df.T[0].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_original_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xgb_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "x = np.linspace(-1000000000,1000000000,1000000000)\n",
    "plt.figure(figsize=(12,12))\n",
    "#plt.scatter(y_train, xgb_train_predictions, c='red', alpha=.95)\n",
    "plt.scatter(y_test, xgb_test_predictions, c='blue', alpha=.95)\n",
    "plt.scatter(y_test, y_original_budget, c='green', alpha=.95)\n",
    "plt.plot(x,x,c='black')\n",
    "plt.xlim([-5,1000000000])\n",
    "plt.ylim([-5,1000000000])\n",
    "plt.xlabel('observations')\n",
    "plt.ylabel('predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create h2o frame for training data\n",
    "training_frame = pd.concat([X_train,y_train], axis=1)\n",
    "training_frame.columns = list(training_frame.columns[:-1]) + ['Actuals']\n",
    "training_frame = h2o.H2OFrame(training_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create h2o frame for testing data\n",
    "testing_frame = pd.concat([X_test,y_test], axis=1)\n",
    "testing_frame.columns = list(testing_frame.columns[:-1]) + ['Actuals']\n",
    "testing_frame = h2o.H2OFrame(testing_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(None, 'Actuals', training_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_actuals = aml.predict(h2o.H2OFrame(pd.concat([X_test, y_test], axis=1)))\n",
    "np.sqrt(np.mean((predicted_actuals['predict'].as_data_frame()['predict'].values-y_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3:55 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(y_train, aml.predict(training_frame).as_data_frame()['predict'].values, c='red')\n",
    "plt.scatter(y_test, aml.predict(testing_frame).as_data_frame()['predict'].values, c='blue')\n",
    "#plt.scatter(train_df['voyage_duration'], train_df['eta_diff'], c='green')\n",
    "plt.plot(x,x,c='black')\n",
    "plt.xlim([-5,100000000])\n",
    "plt.ylim([-5,100000000])\n",
    "plt.xlabel('observations')\n",
    "plt.ylabel('predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9/4 4:42pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
